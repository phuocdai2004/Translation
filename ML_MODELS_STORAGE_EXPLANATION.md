# ğŸ¤– MÃ´ HÃ¬nh Machine Learning - NÆ¡i LÆ°u Trá»¯

## ğŸ“ TÃ³m Táº¯t Nhanh

Project sá»­ dá»¥ng **3 mÃ´ hÃ¬nh ML chÃ­nh**, Ä‘Æ°á»£c táº£i tá»« **Hugging Face Hub** vÃ  lÆ°u táº¡i:

| MÃ´ HÃ¬nh | Chá»©c NÄƒng | NÆ¡i LÆ°u | Format |
|--------|---------|--------|--------|
| **Helsinki-NLP/opus-mt-en-vi** | Dá»‹ch English â†’ Vietnamese | Hugging Face Cache | PyTorch |
| **Helsinki-NLP/opus-mt-vi-en** | Dá»‹ch Vietnamese â†’ English | Hugging Face Cache | PyTorch |
| **Sentence-Transformers/all-MiniLM-L6-v2** | Táº¡o embeddings (semantic search) | Hugging Face Cache | PyTorch |

---

## ğŸ” Chi Tiáº¿t Vá» CÃ¡c MÃ´ HÃ¬nh

### 1. **Helsinki-NLP/opus-mt-en-vi** - Dá»‹ch Anh â†’ Viá»‡t

**ThÃ´ng Tin:**
- Source: Hugging Face Hub
- Task: Machine Translation (EN â†’ VI)
- Framework: Hugging Face Transformers
- Kiáº¿n TrÃºc: Transformer (Seq2Seq)
- ÄÆ°á»£c huáº¥n luyá»‡n bá»Ÿi: Helsinki-NLP

**KÃ­ch ThÆ°á»›c:**
- Model file: ~300-400 MB
- Download láº§n Ä‘áº§u: ~500-600 MB
- Ram khi cháº¡y: ~400-500 MB

**CÃ¡ch Sá»­ Dá»¥ng:**
```python
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

model_name = "Helsinki-NLP/opus-mt-en-vi"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# Sá»­ dá»¥ng
inputs = tokenizer("Hello world", return_tensors="pt")
outputs = model.generate(**inputs)
result = tokenizer.decode(outputs[0], skip_special_tokens=True)
```

### 2. **Helsinki-NLP/opus-mt-vi-en** - Dá»‹ch Viá»‡t â†’ Anh

**ThÃ´ng Tin:**
- Source: Hugging Face Hub
- Task: Machine Translation (VI â†’ EN)
- Framework: Hugging Face Transformers
- Kiáº¿n TrÃºc: Transformer (Seq2Seq)

**KÃ­ch ThÆ°á»›c:**
- Model file: ~300-400 MB (tÆ°Æ¡ng tá»± mÃ´ hÃ¬nh trÃªn)
- Download láº§n Ä‘áº§u: ~500-600 MB
- Ram khi cháº¡y: ~400-500 MB

### 3. **Sentence-Transformers/all-MiniLM-L6-v2** - Táº¡o Embeddings

**ThÃ´ng Tin:**
- Source: Hugging Face Hub
- Task: Semantic Similarity / Embeddings
- Framework: Sentence-Transformers
- Kiáº¿n TrÃºc: BERT-based (6 layers, 22.7M parameters)
- Output: 384 chiá»u vectors

**KÃ­ch ThÆ°á»›c:**
- Model file: ~33 MB (nhá» nháº¥t)
- Download láº§n Ä‘áº§u: ~60-80 MB
- Ram khi cháº¡y: ~150-200 MB

**Æ¯u Äiá»ƒm:**
- Nhanh nháº¥t (MiniLM = Mini Language Model)
- ChÃ­nh xÃ¡c cho semantic tasks
- Nhá» nháº¥t, tá»‘i Æ°u cho inference
- Há»— trá»£ 50+ ngÃ´n ngá»¯

---

## ğŸ’¾ NÆ¡i LÆ°u Trá»¯ CÃ¡c MÃ´ HÃ¬nh

### **Hugging Face Cache Directory**

MÃ´ hÃ¬nh Ä‘Æ°á»£c lÆ°u táº¡i:

```
Windows:
C:\Users\<USERNAME>\.cache\huggingface\hub\

Linux/Mac:
~/.cache/huggingface/hub/
```

### **Cáº¥u TrÃºc ThÆ° Má»¥c**

```
C:\Users\<USERNAME>\.cache\huggingface\hub\
â”œâ”€â”€ models--Helsinki-NLP--opus-mt-en-vi/
â”‚   â”œâ”€â”€ snapshots/
â”‚   â”‚   â””â”€â”€ <commit-hash>/
â”‚   â”‚       â”œâ”€â”€ config.json
â”‚   â”‚       â”œâ”€â”€ pytorch_model.bin       (model weights)
â”‚   â”‚       â”œâ”€â”€ tokenizer.json
â”‚   â”‚       â”œâ”€â”€ source.spm
â”‚   â”‚       â””â”€â”€ target.spm
â”‚   â””â”€â”€ blobs/
â”‚       â””â”€â”€ ... (model files)
â”‚
â”œâ”€â”€ models--Helsinki-NLP--opus-mt-vi-en/
â”‚   â””â”€â”€ (tÆ°Æ¡ng tá»± trÃªn)
â”‚
â””â”€â”€ models--sentence-transformers--all-MiniLM-L6-v2/
    â”œâ”€â”€ snapshots/
    â”‚   â””â”€â”€ <commit-hash>/
    â”‚       â”œâ”€â”€ config.json
    â”‚       â”œâ”€â”€ pytorch_model.bin       (model weights)
    â”‚       â”œâ”€â”€ sentence_bert_config.json
    â”‚       â”œâ”€â”€ tokenizer.json
    â”‚       â””â”€â”€ modules.json
    â””â”€â”€ blobs/
        â””â”€â”€ ... (model files)
```

### **VÃ­ Dá»¥ ÄÆ°á»ng Dáº«n Äáº§y Äá»§**

```
C:\Users\PhuocDai\.cache\huggingface\hub\
models--Helsinki-NLP--opus-mt-en-vi\
snapshots\ABC123DEF456\
pytorch_model.bin               (300-400 MB)
```

---

## ğŸ”„ CÃ¡ch Táº£i MÃ´ HÃ¬nh

### **Táº£i Láº§n Äáº§u (Lazy Loading)**

Khi backend khá»Ÿi Ä‘á»™ng:

```python
# 1. File main.py tÃ¬m tháº¥y yÃªu cáº§u dá»‹ch
# 2. Tá»± Ä‘á»™ng táº£i model tá»« Hugging Face
# 3. LÆ°u vÃ o cache local (C:\Users\..\.cache\huggingface\hub\)
# 4. Láº§n tiáº¿p theo dÃ¹ng tá»« cache (nhanh hÆ¡n)
```

**Táº¡i File:**
- `e:\haystack\backend\app\routes\translation_routes.py`
- `e:\haystack\backend\app\routes\search_routes.py`

```python
def load_translation_models():
    # Auto download tá»« Hugging Face náº¿u chÆ°a cÃ³
    tokenizer = AutoTokenizer.from_pretrained("Helsinki-NLP/opus-mt-en-vi")
    model = AutoModelForSeq2SeqLM.from_pretrained("Helsinki-NLP/opus-mt-en-vi")
```

### **Embedding Model (Sentence Transformers)**

**Táº¡i File:**
- `e:\haystack\backend\app\services\embedding_service.py` (dÃ²ng 45)

```python
embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
```

---

## ğŸ“Š KÃ­ch ThÆ°á»›c Tá»•ng Cá»™ng

| MÃ´ HÃ¬nh | Download Size | Disk Space | RAM Usage |
|--------|-------------|-----------|-----------|
| Helsinki ENâ†’VI | ~500 MB | ~300 MB | ~400 MB |
| Helsinki VIâ†’EN | ~500 MB | ~300 MB | ~400 MB |
| MiniLM Embeddings | ~60 MB | ~33 MB | ~150 MB |
| **Total** | **~1.1 GB** | **~633 MB** | **~950 MB** |

---

## ğŸŒ Hugging Face Hub

### LiÃªn Káº¿t Download

1. **Helsinki-NLP OPUS-MT EN-VI**
   ```
   https://huggingface.co/Helsinki-NLP/opus-mt-en-vi
   ```

2. **Helsinki-NLP OPUS-MT VI-EN**
   ```
   https://huggingface.co/Helsinki-NLP/opus-mt-vi-en
   ```

3. **Sentence Transformers MiniLM**
   ```
   https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
   ```

---

## âš™ï¸ Cáº¥u HÃ¬nh Trong Project

### **File: `e:\haystack\backend\download_models.py`**

```python
print("Required models:")
print("- Helsinki-NLP/opus-mt-en-vi (English to Vietnamese)")
print("- Helsinki-NLP/opus-mt-vi-en (Vietnamese to English)")
print("- sentence-transformers/all-MiniLM-L6-v2 (Embeddings)")
print("\nModels will be downloaded automatically on first API call.")
```

### **NÆ¡i Sá»­ Dá»¥ng**

1. **Translation Route** (`translation_routes.py`)
   ```python
   Helsinki-NLP/opus-mt-en-vi  â†’ /api/translate (ENâ†’VI)
   Helsinki-NLP/opus-mt-vi-en  â†’ /api/translate (VIâ†’EN)
   ```

2. **Embedding Service** (`embedding_service.py`)
   ```python
   sentence-transformers/all-MiniLM-L6-v2 â†’ /api/documents/search
   ```

---

## ğŸ”„ Luá»“ng Táº£i MÃ´ HÃ¬nh

### Khi Báº¡n Dá»‹ch VÄƒn Báº£n

```
1. User gá»­i request dá»‹ch
   â†“
2. Backend check cache (~/.cache/huggingface/)
   â”œâ”€ Náº¿u cÃ³ â†’ DÃ¹ng luÃ´n (nhanh)
   â””â”€ Náº¿u khÃ´ng â†’ Download tá»« Hugging Face
   â†“
3. Load model vÃ o RAM
   â†“
4. Dá»‹ch text
   â†“
5. Tráº£ vá» káº¿t quáº£
```

### Khi Báº¡n TÃ¬m Kiáº¿m Document

```
1. User nháº­p query tÃ¬m kiáº¿m
   â†“
2. Backend check cache embeddings model
   â”œâ”€ Náº¿u cÃ³ â†’ DÃ¹ng luÃ´n
   â””â”€ Náº¿u khÃ´ng â†’ Download tá»« Hugging Face
   â†“
3. Chuyá»ƒn query thÃ nh vector (384 dims)
   â†“
4. TÃ¬m kiáº¿m trong ANNOY index
   â†“
5. Tráº£ vá» káº¿t quáº£ tÆ°Æ¡ng tá»±
```

---

## ğŸ¯ Giáº£i ThÃ­ch Chi Tiáº¿t

### **Táº¡i Sao CÆ¡ Äá»‹a Hugging Face?**

âœ… **Miá»…n phÃ­** - Táº¥t cáº£ mÃ´ hÃ¬nh Ä‘á»u open-source
âœ… **ÄÃ¡ng tin cáº­y** - ÄÆ°á»£c sá»­ dá»¥ng bá»Ÿi hÃ ng triá»‡u developer
âœ… **Cáº­p nháº­t thÆ°á»ng xuyÃªn** - LuÃ´n cÃ³ phiÃªn báº£n má»›i tá»‘t hÆ¡n
âœ… **Há»— trá»£ tá»‘t** - Community lá»›n, documentation chi tiáº¿t
âœ… **Quáº£n lÃ½ dá»…** - Tá»± Ä‘á»™ng download, cache locally

### **Táº¡i Sao Nhá»¯ng MÃ´ HÃ¬nh NÃ y?**

| MÃ´ HÃ¬nh | LÃ½ Do Chá»n |
|--------|-----------|
| **Helsinki OPUS-MT** | SOTA (State-of-the-art) cho dá»‹ch EN-VI, VI-EN |
| **MiniLM** | Nhá», nhanh, chÃ­nh xÃ¡c cho semantic search |

---

## ğŸ’¡ CÃ¡ch Download Thá»§ CÃ´ng

Náº¿u muá»‘n táº£i trÆ°á»›c mÃ´ hÃ¬nh (khÃ´ng Ä‘á»£i khi dÃ¹ng):

```bash
# Command 1: Download ENâ†’VI
python -c "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM; AutoTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-vi'); AutoModelForSeq2SeqLM.from_pretrained('Helsinki-NLP/opus-mt-en-vi')"

# Command 2: Download VIâ†’EN  
python -c "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM; AutoTokenizer.from_pretrained('Helsinki-NLP/opus-mt-vi-en'); AutoModelForSeq2SeqLM.from_pretrained('Helsinki-NLP/opus-mt-vi-en')"

# Command 3: Download Embeddings
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
```

---

## ğŸ“ TÃ³m LÆ°á»£c NÆ¡i LÆ°u

### **MÃ´ HÃ¬nh (Models)**
```
~/.cache/huggingface/hub/
â”œâ”€â”€ models--Helsinki-NLP--opus-mt-en-vi/
â”œâ”€â”€ models--Helsinki-NLP--opus-mt-vi-en/
â””â”€â”€ models--sentence-transformers--all-MiniLM-L6-v2/
```

### **Tokenizers**
```
~/.cache/huggingface/hub/
â”œâ”€â”€ models--Helsinki-NLP--opus-mt-en-vi/
â”‚   â””â”€â”€ snapshots/.../tokenizer.json
â”œâ”€â”€ models--Helsinki-NLP--opus-mt-vi-en/
â”‚   â””â”€â”€ snapshots/.../tokenizer.json
â””â”€â”€ models--sentence-transformers--all-MiniLM-L6-v2/
    â””â”€â”€ snapshots/.../tokenizer.json
```

### **Dá»¯ Liá»‡u KhÃ¡c Cá»§a Project**
```
e:\haystack\
â”œâ”€â”€ documents.db              (Dá»¯ liá»‡u document)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ annoy.index          (Vector index)
â”‚   â””â”€â”€ doc_mapping.json     (Metadata mapping)
â””â”€â”€ backend/
    â””â”€â”€ app/
        â”œâ”€â”€ models/          (Data models - Pydantic, khÃ´ng pháº£i ML models)
        â””â”€â”€ services/        (Code dÃ¹ng ML models)
```

---

## ğŸ“ CÃ¢u Tráº£ Lá»i Cho Tháº§y

**Tháº§y há»i: "MÃ´ hÃ¬nh nÃ³ Ä‘Ã¢u?"**

**CÃ¢u tráº£ lá»i:**

> Project sá»­ dá»¥ng **3 mÃ´ hÃ¬nh Machine Learning**:
>
> 1. **Helsinki-NLP/opus-mt-en-vi** - Dá»‹ch Anh â†’ Viá»‡t
> 2. **Helsinki-NLP/opus-mt-vi-en** - Dá»‹ch Viá»‡t â†’ Anh  
> 3. **sentence-transformers/all-MiniLM-L6-v2** - Táº¡o vector embeddings
>
> **NÆ¡i LÆ°u:**
> - MÃ´ hÃ¬nh Ä‘Æ°á»£c **táº£i tá»« Hugging Face Hub** (online) láº§n Ä‘áº§u
> - Sau Ä‘Ã³ **lÆ°u vÃ o cache local** táº¡i:
>   - **Windows:** `C:\Users\<USERNAME>\.cache\huggingface\hub\`
>   - **Linux/Mac:** `~/.cache/huggingface/hub\`
> - Tá»•ng dung lÆ°á»£ng: **~1.1 GB** (download), **~633 MB** (Ä‘Ä©a)
>
> **CÃ¡ch Hoáº¡t Äá»™ng:**
> - Láº§n Ä‘áº§u dÃ¹ng: Download tá»« Hugging Face (~5-10 phÃºt tÃ¹y máº¡ng)
> - Láº§n sau: DÃ¹ng tá»« cache local (nhanh gáº¥p 100 láº§n)
> - MÃ´ hÃ¬nh tá»± Ä‘á»™ng load khi cáº§n (lazy loading)
>
> **Loáº¡i MÃ´ HÃ¬nh:**
> - Translation: Transformer-based Seq2Seq (Helsinki-NLP)
> - Embeddings: BERT-based (Sentence Transformers)

---

## ğŸ“š TÃ i Liá»‡u ThÃªm

- **Hugging Face Hub:** https://huggingface.co
- **Transformers Library:** https://huggingface.co/docs/transformers
- **Sentence Transformers:** https://www.sbert.net

---

**Status:** âœ… **MÃ” HÃŒNH LÆ¯U TRá»® Táº I HUGGING FACE HUB & LOCAL CACHE**
